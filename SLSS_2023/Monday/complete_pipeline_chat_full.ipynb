{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586248df",
   "metadata": {},
   "source": [
    "## Retrieval augmented generation\n",
    " \n",
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution. \n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334357c",
   "metadata": {},
   "source": [
    "![](overview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d106d9c42f42f",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5343d8b3358f3",
   "metadata": {},
   "source": [
    "![](data_loading_sources.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694fa96",
   "metadata": {},
   "source": [
    "### Loaders\n",
    "* Loaders deal with the specifics of accessing and converting data\n",
    "    * Accessing\n",
    "        * Web Sites\n",
    "        * Data Bases\n",
    "        * YouTube arXiv\n",
    "        * ...\n",
    "    * Data Types\n",
    "        * PDF\n",
    "        * HTML\n",
    "        * JSON\n",
    "        * Word, PowerPoint...\n",
    "* Returns a list of 'Document objects:\n",
    "\n",
    "[<br>\n",
    "Document (page_content='MachineLearning-Lecture01 \\nInstructor (Andrew Ng): Okay.<br>\n",
    "Good morning. Welcome to CS229.<br>\n",
    "metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf, 'page': 0})<br>\n",
    "...<br>\n",
    "Document (page_content='[End of Audio] \\Duration: 69 minutes<br>\n",
    "metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf, 'page': 21})<br>\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284cc8a",
   "metadata": {},
   "source": [
    "Each page is a `Document`.\n",
    "\n",
    "A `Document` contains text (`page_content`) and `metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a249fa3b63fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key  = \"paste-your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38baf6d3",
   "metadata": {},
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef5d48",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/00.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28c723-3625-4219-b0f8-8d5b761ae79e",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94e3b5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d0932",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead28868",
   "metadata": {},
   "source": [
    "### YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f360f",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a78e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835edd9",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install yt_dlp\n",
    "# ! pip install pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa8f7a-bd04-4bbd-96a9-8c2088426885",
   "metadata": {},
   "source": [
    "**Note**: This can take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ecc18",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=VcPMLDu7BTs\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "video_content = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf39c3",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_content[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_content[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54e6f9",
   "metadata": {},
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7f5d4",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c8f4e-6fd5-4230-9dfc-84e100e90d72",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039f8ed-ebc1-44e7-829a-9499dc5d1f03",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40094b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2765b5b03ef194",
   "metadata": {},
   "source": [
    "# Document Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3a247",
   "metadata": {},
   "source": [
    "![](document_splitting.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492cba024fd3485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2a947d6fb324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27fab9b3355de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811b837ac8b5ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973a76bc213f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62b28e529db004",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ab88cfd4f7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29309e1812603826",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9329fe6786c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6919d21870be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe49f2d2d8ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd115e8b7344397",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c83cde0972936",
   "metadata": {},
   "source": [
    "Let's reduce the chunk size a bit and add a period to our separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc80d35930f4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"],\n",
    "    is_separator_regex = True\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbce76f62eb096",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "    is_separator_regex = True\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b525834f24e8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    # separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "    separators=[\"\\n\\n\", \"(?<=\\. )\", \"\\n\", \" \", \"\"],\n",
    "    is_separator_regex = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7a096713b7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = r_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e90e1da9b01437",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3251a8b6d4d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[4].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215acf7dfcc7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter newline chars from all the documents\n",
    "for doc in docs:\n",
    "    doc.page_content = doc.page_content.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e22211a353370",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[4].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb1391825863af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all PDF\n",
    "loaders = [PyPDFLoader(f\"docs/{file}\") for file in os.listdir('docs') if file.endswith('.pdf')]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    pdf_docs = loader.load()\n",
    "    docs += pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6088efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844da49f8c7b66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150,\n",
    "    separators=[\"\\n\\n\", \"(?<=\\. )\", \"\\n\", \" \", \"\"],\n",
    "    is_separator_regex = True\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "for doc in splits:\n",
    "    doc.page_content = doc.page_content.replace(\"\\n\", \" \").replace('- ', \"\")\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a990b9ae398f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d11494aa84d74b",
   "metadata": {},
   "source": [
    "# Vectorstores and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1d8e8",
   "metadata": {},
   "source": [
    "![](embeddings.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2eb0bfd4ad59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if you have paid version of OpenAI \n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# embedding = OpenAIEmbeddings(openai_api_key=\"paste-your-api-key-here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if you don't have paid version of OpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "model_id = 'sentence-transformers/all-mpnet-base-v2'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_id,\n",
    "    model_kwargs=model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b5c06ed7f8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4efc72c5c54e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2107da17f9ddb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feafbdbe41d3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93113483ded4ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9dab301d3d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a2af773b8cfdd",
   "metadata": {},
   "source": [
    "### Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8140915d11627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943a7b038654be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e2fc11c6ee09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493906cf6bf57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425ddfd7599af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84b37e817338ae",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d13f3f0266af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can IMBH grow in mass?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924b3d3b5b310ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question, k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db7e531492bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9c97322c5fbd7",
   "metadata": {},
   "source": [
    "Let's save this so we can use it later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e05ccce559bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "534a859bded80d18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](overview.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f21fe12144d34eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Can we provide full text as a context for GPT? Estimate it!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4899fa419aa79739"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"I like space and IT, that's why I came to Space summer school in Kosice.\",\n",
    "    \"Black holes are an interesting phenomenon to study.\",\n",
    "    \"Typically, there's a supermassive black hole sitting in the middle of a galaxy.\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a0788170b637226"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fe701280f2070e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Tell me something interesting about black holes.\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a50a7df3ac87730e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b522f90434ea73f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f02c60f15842cc32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3, lambda_mult=0.5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9395ab95f1834e48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"What are some physical properties of IMBH?\"\n",
    "docs_ss = vectordb.similarity_search(question, k=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0e773d3e4e27718"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_ss[0].page_content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7227e3a318b810c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_ss[1].page_content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "123fa715c5fac759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question, k=3, fetch_k=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc19ee73309be87c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_mmr[0].page_content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf5dad838a214d7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_mmr[1].page_content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b08a876317c0b78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Addressing Specificity: working with metadata\n",
    "\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb185e306abf980c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"What do they say about IMBH on the first page of the fifth document?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bac76ba981679a60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "splits[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a3c0cd02f863531"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/04.pdf\", \"page\": 1}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1434910a789defc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f15648dbeb0fac6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d4bb13fb306a368"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebcd6bdc6a390c1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.chat_models import ChatOpenAI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f0d3476b440e16f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The scientific paper the chunk is from, should be one of `docs/00.pdf`, `docs/01.pdf`, `docs/02.pdf`, `docs/03.pdf`, `docs/04.pdf`, `docs/05.pdf`, `docs/06.pdf`, `docs/07.pdf`, `docs/08.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page of the scientific paper\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf7d3a93a8a9e83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_name = \"gpt-3.5-turbo\"\n",
    "document_content_description = \"Scientific paper about black holes\"\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb6ad464eb3fb757"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"What do they say about IMBH on the first page of the fifth document?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7be28e1d2e147288"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7de9710c57335bf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "358b66a0937b2911"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcbe24485d0217eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319e19af2339f4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2531df6f544de512"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_retriever = SVMRetriever.from_texts([el.page_content for el in splits], embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts([el.page_content for el in splits])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c5cf972fbd425c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"What is a typical size of IMBH?\"\n",
    "docs_svm = svm_retriever.get_relevant_documents(question)\n",
    "docs_svm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec27f0a59293b0ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"What is a typical size of IMBH?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb4b422cdf13ad25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question Answering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9a0acb77f46f4ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_name = \"gpt-3.5-turbo\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42be154480e7c8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key=\"paste-your-api-key-here\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebd66c56c219ed62"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RetrievalQA chain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c737055105f70fc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4079516db8700e54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5, \"distance_metric\": \"cos\"})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48183abb92c02d82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Tell me something interesting about IMBH.\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e4017f78f28503e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"How do IMBH compare to super-massive black holes?\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35109f81d3b3e6c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result['source_documents']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83647e1ba6ba1030"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Which type of black holes are the most common?\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f0d2cbc217669ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"What is a typical density of IMBH?\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c91bc65a764ae644"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"What is a typical size of IMBH?\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb162fc4664b1f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Do we have some IMBH in our galaxy?\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e90db5e33f370"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4828b586625d3797"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Default prompts:\n",
    "https://github.com/samrawal/langchain-prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f407eec915a99c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea1133713d224c3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 8, \"distance_metric\": \"cos\"}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cf717543c16783e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"How do IMBH compare to super-massive black holes?\"})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "172d437601ba083"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Advanced chain types - MapReduce, Refine"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d385e1409fc16ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![overview.jpeg](map_reduce_refine.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e55d6a989ee18190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "query = \"What are some methods to study the formation of IMBH?\"\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 8, \"distance_metric\": \"cos\"})\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"map_reduce\", return_map_steps=True)\n",
    "ans = chain({\"input_documents\": docs, \"question\": query})  # , return_only_outputs=True)\n",
    "ans['output_text']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b476efb49b64e5dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ans['intermediate_steps']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dfdd31aaa82c4a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"What are some methods to study the formation of IMBH?\"\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 8, \"distance_metric\": \"cos\"})\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"refine\", return_intermediate_steps=True)\n",
    "ans = chain({\"input_documents\": docs, \"question\": query})  # , return_only_outputs=True)\n",
    "ans['output_text']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d84a54f3be9c0bb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ans['intermediate_steps']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f6ab1f125062af2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat\n",
    "\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5febddeddfb5438a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![overview.jpeg](overview.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f1b31288a566222"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# by default, there's no memory!\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 8, \"distance_metric\": \"cos\"})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": \"Tell me something interesting about IMBH.\"})\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "result = qa_chain({\"query\": \"Which of these theories is the most popular among scientists?\"})\n",
    "print(result[\"result\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9f9980ab5c8e2f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Memory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc4137c6a1314f35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55071b1c36f77879"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationalRetrievalChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5abd5bc5eaf6350a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e031cdd1ef8844bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Tell me something interesting about IMBH.\"\n",
    "result = qa({\"question\": question})\n",
    "result['answer']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ab5654c1ba8320"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Which of these theories is the most popular among scientists?\"\n",
    "result = qa({\"question\": question})\n",
    "result['answer']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca07e01f4bb85365"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
